.. _caches:

------------------------
Software-Managed Caches
------------------------

:term:`Software-Managed Caches<Software-Managed Cache>` are syntax elements that are used
to describe data reuse pattern of the stencil computations.
They are an essential functionality of the |GT| in order
to deliver an efficient implementation of memory bound codes,
since the library uses
this information to allocate cached fields in a fast on-chip
scratch-pad memory.

In computing architectures like NVIDIA GPUs, where the use of
the different on-chip memory hierarchy must be explicitly
declared using the CUDA programming model, the use of :term:`Software-Managed
Caches<Software-Managed Cache>` of |GT| increases the data locality of stencil algorithms
and provides a significant performance speedup.

While the library is capable of exploiting several on-chip memory layers
(like texture cache, const cache, shared memory, and registers of NVIDIA GPUs)
the |GT| language is abstracting these underlying memory layers and
exposes syntax elements that are computing architecture agnostic.

Therefore the :term:`Software-Managed Cache` syntax should be used by the
user to describe *only* data reuse patterns, and not type of
on-chip memory that should be exploited (which is a decision delegated to
the computing architecture backend of the library).

An example of the syntax for caching certain fields of a
computation is shown below

.. code-block:: gridtools

 auto comp = make_computation<backend_t>(
    grid,
    make_multistage(
        execute::parallel(),
        define_caches(cache<cache_type::ij, cache_io_policy::local>(p_f1(), p_f2())),
        make_stage<lap_function>(p_f1(), p_f2(), p_in()),
        make_stage<lap_function>(p_out(), p_f1(), p_f2())
    )
 );

The :term:`Cache` DSL elements are enclosed into a ``define_caches`` construct,
that accept any number of ``cache`` constructs. At the same time, each
``cache`` construct can specify multiple fields that shared the same
access pattern.

.. note::

 It is important to note that the ``cache`` specifications
 are prescribing the behavior of the library: if a :term:`Cache`
 is specified, a :term:`Cache` will be used. In the rare case of
 using too many :term:`Caches<Cache>` a decrease in performance might be
 observed due to saturation of available resources


The ``cache`` construct adheres to the following syntax:

.. code-block:: gridtools

 cache<cache_type, cache_io_policy>(p_args...)

where ``p_args...`` is a list of placeholders for which the specified caching
should be used.
Full examples on :term:`Cache` usages can be found in the source code in the
`horizontal diffusion <https://github.com/GridTools/gridtools/blob/master/gt_examples/stencil_composition/horizontal_diffusion_limited.cpp>`_
and
`vertical advection <https://github.com/GridTools/gridtools/blob/master/regression/vertical_advection_dycore.cpp>`_.

We now describe the details of each element of the ``cache`` constructs.

.. _cache-type:

^^^^^^^^^^^^^^^^^^^^^^
Cache Type
^^^^^^^^^^^^^^^^^^^^^^

The ``cache_type`` describes the type of access pattern present in our stencil for the field being cached. It's
value can be one of the following (where we indicate the basic mean of implementation on the GPUs, so that the user can understand the amount of resources involved):

#.  ``cache_type::ij``: cache data fields whose access pattern lies in the ij-plane, i.e. only offsets of the type `i ±
    X` or `j ± Y` are allowed (the GPU backend will cache these fields in shared memory). It is undefined behaviour to
    access data with k-offsets.

#.  ``cache_type::k``: cache data field whose access pattern is restricted to the k-direction, i.e. only offsets of the
    type `k ± Z` (the GPU backend will cache these fields in registers). It is undefined behaviour to access data with
    offsets in i or j direction.


.. _cache-policy:

^^^^^^^^^^^^
Cache Policy
^^^^^^^^^^^^

The ``cache_policy`` specifies a synchronization policy between the data in the :term:`Cache` and the data in main memory. A scratch-pad can be used
in order to allocate temporary computations that do not require data persistency across multiple stencils. However often the data that is
being cached is already present in main memory fields. In this case, the :term:`Software-Managed Caches<Software-Managed Cache>` of |GT| gives the possibility
to specify a cache policy that allows to synchronize the main memory with the cached field.
The possible values are:

#. ``cache_io_policy::fill``: fill the scratch-pad buffer with data from main memory field before use.

#. ``cache_io_policy::flush``: After the execution of the stencil operators the data in the :term:`Cache` is written back into the main memory fields.

#. ``cache_io_policy::fill_and_flush``: The combination of ``fill`` and ``flush``

#. ``cache_io_policy::local``: The scratch-pad data is not persistent and only available within the scope of a
   multi-stage. Local caches are only meaningful in connection with temporary arguments.

 :numref:`fig_kcache_ex` graphically depicts an example of all the ordered operations that are executed when a ``fill_and_flush``
 :term:`Cache` is used in a forward vertical loop.
 
.. _fig_kcache_ex:
.. figure:: figures/kcache_ex.png
   :scale: 50 %

   Representation of an implementation for a ``cache<cache_type::k, cache_io_policy::fill_and_flush>`` that is used within a
   stencil with :term:`Extent` ``<-2, 1>`` in the vertical dimension and implemented as a ring-buffer with 4 levels (in order to allocate all possible offsetted accesses). The three operations
   are triggered automatically by the library for a `fill_and_flush` :term:`Cache` when the vertical loop transition from level 9 to level 10.
