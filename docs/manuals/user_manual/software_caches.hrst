.. _caches:

------------------------
Software Managed Caches
------------------------

Software managed caches are syntax elements that are used
to describe data reuse pattern of the stencil computations.
They are an essential functionality of the |GT| in order
to deliver an efficient implementation of memory bound codes,
since the library uses
this information to allocate cached fields in a fast on-chip
scratch-pad memory.

In computing architectures like NVIDIA GPUs, where the use of
the different on-chip memory hierarchy must be explicitly
declared using the CUDA programming model, the use of software managed
caches of |GT| increases the data locality of stencil algorithms
and provides a significant performance speedup.

While the library is capable of exploiting several on-chip memory layers
(like texture cache, const cache, shared memory, and registers of NVIDIA GPUs)
the |GT| language is abstracting these underlying memory layers and
exposes syntax elements that are computing architecture agnostic.

Therefore the software managed cache syntax should be used by the
user to describe *only* data reuse patterns, and not type of
on-chip memory that should be exploited (which is a decision delegated to
the computing architecture backend of the library).

An example of the syntax for caching certain fields of a
computation is shown below

.. code-block:: gridtools

 auto comp = make_computation<backend_t>(
    grid,
    make_multistage(
        execute::parallel(),
        define_caches(cache<cache_type::ij, cache_io_policy::local>(p_f1(), p_f2())),
        make_stage<lap_function>(p_f1(), p_f2(), p_in()),
        make_stage<lap_function>(p_out(), p_f1(), p_f2())
    )
 );

The cache DSL elements are enclosed into a ``define_caches`` construct,
that accept any number of ``cache`` constructs. At the same time, each
``cache`` construct can specify multiple fields that shared the same
access pattern.

.. note::

 It is important to note that the ``cache`` specifications
 are prescribing the behavior of the library: if a cache
 is specified, a cache will be used. In the rare case of
 using too many caches a decrease in performance might be
 observed due to saturation of available resources


The ``cache`` construct adheres to the following syntax:

.. code-block:: gridtools

 cache<cache_type, cache_io_policy>(p_args...)

where ``p_args...`` is a list of placeholders for which the specified caching
should be used.
Full examples on cache usages can be found in the source code in the
`horizontal diffusion <https://github.com/eth-cscs/gridtools/blob/master/gt_examples/stencil-composition/horizontal_diffusion_limited.cpp>`_
and
`vertical advection <https://github.com/eth-cscs/gridtools/blob/master/regression/vertical_advection_dycore.cpp>`_.

We now describe the details of each element of the cache constructs.

^^^^^^^^^^^^^^^^^^^^^^
Cache Type
^^^^^^^^^^^^^^^^^^^^^^

The ``cache_type`` describes the type of access pattern present in our stencil for the field being cached. It's
value can be one of the following (where we indicate the basic mean of implementation on the GPUs, so that the user can understand the amount of resources involved):

#.  ``IJ``: cache data fields whose access pattern lies in the ij-plane, i.e. only offsets of the type `i ± X` or `j ± Y` are allowed (the GPU backend will cache these fields in shared memory).

#.  ``K``: cache data field whose access pattern is restricted to the
    k-direction, i.e. only offsets of the type `k ± Z` (the GPU backend will cache these fields in registers).

.. note::

 An error in the specification of the ``cache_type``, for example using ``IJ`` for a field that is accessed with k offsets will lead to compile time errors.

^^^^^^^^^^^^
Cache Policy
^^^^^^^^^^^^

The ``cache_policy`` specifies a synchronization policy between the data in the cache and the data in main memory. A scratch-pad can be used
in order to allocate temporary computations that do not require data persistency across multiple stencils. However often the data that is
being cached is already present in main memory fields. In this case, the software managed caches of |GT| gives the possibility
to specify a cache policy that allows to synchronize the main memory with the cached field.
The possible values are:

#. ``fill``: fill the scratch-pad buffer with data from main memory field before use.

#. ``flush``: After the execution of the stencil operators the data in the cache is written back into the main memory fields.

#. ``fill_and_flush``: The combination of ``fill`` and ``flush``

#. ``local``: The scratch-pad data is not persistent and only available within the scope of a multi-stage.

 :numref:`fig_kcache_ex` graphically depicts an example of all the ordered operations that are executed when a ``fill_and_flush``
  cache is used in a forward vertical loop. 
 
.. _fig_kcache_ex:
.. figure:: figures/kcache_ex.png
   :scale: 50 %

   Representation of an implementation for a ``cache<cache_type::k, cache_io_policy::fill_and_flush>`` that is used within a
   stencil with extent ``<-2, 1>`` in the vertical dimension and implemented as a ring-buffer with 4 levels (in order to allocate all possible offsetted accesses). The three operations
   are triggered automatically by the library for a `fill_and_flush` cache when the vertical loop transition from level 9 to level 10.
